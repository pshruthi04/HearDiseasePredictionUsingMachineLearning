{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a7192a",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89588857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.android', '.atom', '.bash_history', '.cache', '.conda', '.config', '.dataloader', '.dbshell', '.eclipse', '.emulator_console_auth_token', '.gitconfig', '.gradle', '.idea', '.ipynb_checkpoints', '.ipython', '.jdks', '.jupyter', '.lemminx', '.lesshst', '.m2', '.matplotlib', '.mongorc.js', '.ms-ad', '.nbi', '.openjfx', '.p2', '.spyder-py3', '.ssh', '.sts4', '.viminfo', '.VirtualBox', '.vscode', '3D Objects', 'android', 'AndroidStudioProjects', 'AppData', 'Application Data', 'ass.py', 'Assignment0.ipynb', 'Assignment4.ipynb', 'Assignment6.ipynb', 'BB_stats_2000.csv', 'Classification_heart (1).ipynb', 'Clustering.ipynb', 'Cookies', 'dataloader', 'Desktop', 'Documents', 'Downloads', 'ds-venv', 'dsA.csv', 'dsB.csv', 'dsC.csv', 'dsD.csv', 'dsE.csv', 'dsF.csv', 'dsG.csv', 'dsH.csv', 'DT.ipynb', 'eclipse', 'eclipse-workspace', 'Encryption1MAY_5', 'Favorites', 'fn.py', 'Heart.csv', 'IntelGraphicsProfiles', 'Jedi', 'Linear_regression.ipynb', 'Links', 'Local Settings', 'milestone.ipynb', 'Ml_Assignments', 'Music', 'My Documents', 'NetBeansProjects', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{53b39e88-18c4-11ea-a811-000d3aa4692b}.TM.blf', 'NTUSER.DAT{53b39e88-18c4-11ea-a811-000d3aa4692b}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{53b39e88-18c4-11ea-a811-000d3aa4692b}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'Oracle', 'Pictures', 'pizza_orderr.py', 'Postman', 'Postman Agent', 'PrintHood', 'python', 'pythonF22', 'python_basic_structures.ipynb', 'range.py', 'Recent', 'salary.dot', 'salary.eps', 'salary.png', 'Saved Games', 'Searches', 'SendTo', 'Start Menu', 'Templates', 'threeDplot.ipynb', 'tree.dot', 'Untitled.ipynb', 'Videos', '_netrc']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d2a0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data=pd.read_csv('Heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16934447",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_data.iloc[:, :-1].values\n",
    "y = heart_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1c6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "  \n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range =(0, 1))\n",
    "  \n",
    "X_preprocessed = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c662d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X_preprocessed,y,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ef1b4",
   "metadata": {},
   "source": [
    "### K means clustering using elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efda8c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a99f6b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 0 4 1 0 1 4 0 0 4 5 4 2 1 4 1 2 4 4 4 4 4 5 0 1 0 2 3 0 0 2 0 5 2 0 1\n",
      " 4 5 1 1 4 0 5 1 1 4 4 2 4 4 1 4 0 4 0 4 4 0 1 5 1 0 2 0 0 2 4 4 0 4 4 0 4\n",
      " 0 4 4 4 0 4 4 1 1 1 5 3 5 0 0 5 4 0 4 1 2 2 3 4 1 4 4 5 0 4 0 2 5 4 4 4 1\n",
      " 0 1 0 4 0 0 0 0 4 1 4 4 4 0 0 2 1 0 5 0 4 1 4 1 4 2 2 2 5 1 1 0 2 2 5 4 4\n",
      " 4 0 4 2 4 5 4 2 4 0 2 4 4 1 0 0 0 5 2 4 4 0 5 4 1 4 2 2 4 1 2 5 1 2 1 4 5\n",
      " 1 4 5 4 0 1 2 2 5 0 1 4 4 5 4 0 5 5 5 0 4 4 4 2 0 4 5 2 1 4 1 5 1 5 4 3 2\n",
      " 1 5 5 2 5 2 1 1 4 5 1 5 1 1 1 1 1 1 5 5 2 5 2 4 3 5 1 5 1 4 5 1 5 1 5 2 4\n",
      " 4 4 4 5 4 2 2 1 2 5 5 4 4 5 4 5 0 2 5 1 2 1 0 2 4 2 1 0 4 1 2 0 1 4 2 0 2\n",
      " 2 2 5 5 2 2 4 4]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = 6, init = 'k-means++', random_state = 42)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "print(y_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da4a6207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The centroids are  [[4.80754717e+01 6.79245283e-01 1.30188679e+00 1.28886792e+02\n",
      "  1.93660377e+02 1.69811321e-01 6.79245283e-01 1.67283019e+02\n",
      "  1.50943396e-01 7.52830189e-01 1.58490566e+00 4.52830189e-01\n",
      "  2.15094340e+00]\n",
      " [5.55964912e+01 5.78947368e-01 8.42105263e-01 1.35263158e+02\n",
      "  3.10070175e+02 1.40350877e-01 5.26315789e-01 1.53298246e+02\n",
      "  3.68421053e-01 9.96491228e-01 1.52631579e+00 7.71929825e-01\n",
      "  2.33333333e+00]\n",
      " [5.73265306e+01 7.55102041e-01 6.73469388e-01 1.27530612e+02\n",
      "  1.97836735e+02 1.02040816e-01 5.71428571e-01 1.26489796e+02\n",
      "  4.69387755e-01 1.43265306e+00 1.20408163e+00 8.36734694e-01\n",
      "  2.30612245e+00]\n",
      " [6.26000000e+01 0.00000000e+00 8.00000000e-01 1.35800000e+02\n",
      "  4.38200000e+02 2.00000000e-01 0.00000000e+00 1.55600000e+02\n",
      "  2.00000000e-01 1.90000000e+00 1.20000000e+00 1.20000000e+00\n",
      "  2.60000000e+00]\n",
      " [5.23186813e+01 7.14285714e-01 1.08791209e+00 1.29802198e+02\n",
      "  2.42285714e+02 1.42857143e-01 5.27472527e-01 1.63076923e+02\n",
      "  2.19780220e-01 7.86813187e-01 1.49450549e+00 6.59340659e-01\n",
      "  2.30769231e+00]\n",
      " [5.98163265e+01 7.34693878e-01 8.36734694e-01 1.37408163e+02\n",
      "  2.64959184e+02 1.83673469e-01 3.87755102e-01 1.24448980e+02\n",
      "  5.30612245e-01 1.38775510e+00 1.08163265e+00 9.59183673e-01\n",
      "  2.46938776e+00]]\n",
      "Assignments are: \n",
      "[4 4 0 4 1 0 1 4 0 0 4 5 4 2 1 4 1 2 4 4 4 4 4 5 0 1 0 2 3 0 0 2 0 5 2 0 1\n",
      " 4 5 1 1 4 0 5 1 1 4 4 2 4 4 1 4 0 4 0 4 4 0 1 5 1 0 2 0 0 2 4 4 0 4 4 0 4\n",
      " 0 4 4 4 0 4 4 1 1 1 5 3 5 0 0 5 4 0 4 1 2 2 3 4 1 4 4 5 0 4 0 2 5 4 4 4 1\n",
      " 0 1 0 4 0 0 0 0 4 1 4 4 4 0 0 2 1 0 5 0 4 1 4 1 4 2 2 2 5 1 1 0 2 2 5 4 4\n",
      " 4 0 4 2 4 5 4 2 4 0 2 4 4 1 0 0 0 5 2 4 4 0 5 4 1 4 2 2 4 1 2 5 1 2 1 4 5\n",
      " 1 4 5 4 0 1 2 2 5 0 1 4 4 5 4 0 5 5 5 0 4 4 4 2 0 4 5 2 1 4 1 5 1 5 4 3 2\n",
      " 1 5 5 2 5 2 1 1 4 5 1 5 1 1 1 1 1 1 5 5 2 5 2 4 3 5 1 5 1 4 5 1 5 1 5 2 4\n",
      " 4 4 4 5 4 2 2 1 2 5 5 4 4 5 4 5 0 2 5 1 2 1 0 2 4 2 1 0 4 1 2 0 1 4 2 0 2\n",
      " 2 2 5 5 2 2 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"The centroids are \", kmeans.cluster_centers_)\n",
    "\n",
    "print(\"Assignments are: \")\n",
    "print(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46d2d5",
   "metadata": {},
   "source": [
    "### Dimensional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "483846d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components = 1)\n",
    "X_train = lda.fit_transform(X_train, Y_train)\n",
    "X_test = lda.transform(X_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0811b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  6]\n",
      " [ 2 30]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8688524590163934"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc40313",
   "metadata": {},
   "source": [
    "### 3. Visualize and create a narrative about what you have discovered in the data. Don't just be descriptive, think predictively\n",
    "#### As the data is supervised, PCA is not possible. As the data which I considered has only 2 classes for prediction, LDA is not supportable due to the below statement. n_components cannot be larger than min(n_features, n_classes - 1. So, dimensional analysis is not possible. The data can be viewd from clusters. To perform dimensional analysis, we need two axis, x-axis and y-axis. Here, number of classes are two, n_components min(features, n_classes-1) i.e. 2-1=1. min(features, 1), minimum is 1. So, we are getting only one axis, we cannot perform dimensional analysis with one axis.\n",
    "#### As the data do not contain any anomolous data and the data is supervised, we can predict it with any supervised models like random forest, neural nets and regression to get best accuracy. For the dataset, we got 6 clusters as shown above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1330752a",
   "metadata": {},
   "source": [
    "### Anomolous data\n",
    "#### There is no anomolous data for this dataset. Anomaly detection is identifying data points in data that don't fit the normal patterns. We usually perform anomaly detection to make it more effective, especially when large datasets are involved. As explained above. The dataset do not have anomolous data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb2359c",
   "metadata": {},
   "source": [
    "#### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73936e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier1 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier1.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53472a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  7]\n",
      " [ 9 23]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7377049180327869"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = classifier1.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(Y_test, y_pred1)\n",
    "print(cm)\n",
    "accuracy_score(Y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "189a74cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\s545684\\ds-venv\\lib\\site-packages (2.11.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.23.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.27.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.10.26)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.50.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\s545684\\ds-venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6546da2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 2s 3ms/step - loss: 0.7347 - accuracy: 0.5432\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7257 - accuracy: 0.5432\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.5473\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7088 - accuracy: 0.5514\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7003 - accuracy: 0.5514\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5514\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.5514\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.5473\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6663 - accuracy: 0.5473\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.5514\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.5473\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.5391\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.5391\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.5432\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6133 - accuracy: 0.5514\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6043 - accuracy: 0.5720\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.5802\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.5885\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.6502\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.6790\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.7366\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7901\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.8354\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.8313\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.8313\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.8313\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.8313\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.8313\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.8313\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.8313\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.8313\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.8313\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.8313\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.8313\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.8313\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.8354\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.8354\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.8354\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.8354\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.8354\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.8354\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.8354\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.8354\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.8354\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.8354\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.8313\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.8313\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.8313\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.8354\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.8354\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.8354\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.8354\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8395\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8477\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8395\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8477\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8477\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8477\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8477\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8436\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8477\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8395\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8395\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8395\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8395\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.8395\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3545 - accuracy: 0.8395\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8436\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.8436\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8436\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8436\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8436\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8436\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8436\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.8436\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8436\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8436\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8436\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8436\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8436\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8436\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3458 - accuracy: 0.8436\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8436\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8436\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8436\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8436\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8436\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8436\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8436\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8436\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8436\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8436\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8436\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8436\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8436\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8436\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8436\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8436\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8436\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8436\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8436\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8436\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8436\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8436\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8436\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8436\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8436\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3443 - accuracy: 0.8477\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8477\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8436\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8436\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8436\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8436\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8436\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8436\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8395\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8436\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8436\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8436\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8436\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8436\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8436\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8436\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.8436\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8436\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8436\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8436\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.8436\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.8436\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.8436\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.8436\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8436\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8436\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8436\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8436\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8436\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8436\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8436\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8477\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8477\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8477\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8477\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8477\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.8477\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8436\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8477\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8436\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8436\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8436\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8436\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8436\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8477\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8477\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8477\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3419 - accuracy: 0.8477\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8477\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8477\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8477\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8477\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8477\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8477\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8477\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8477\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8477\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8477\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8477\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.8477\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8477\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8436\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8436\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8436\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8436\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8477\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8477\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8477\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8477\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8477\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8477\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8477\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8477\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8477\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8477\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8477\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8477\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8477\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8436\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8436\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8477\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8477\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8477\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8477\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.8477\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8477\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.8477\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8477\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.8477\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.8477\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8477\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8477\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1643bf35780>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann.fit(X_train, Y_train, batch_size = 32, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f7b9a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53ae3bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  6]\n",
      " [ 3 29]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(Y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
